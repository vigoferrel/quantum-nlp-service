# LocalGPT - InstalaciÃ³n y Uso en EspaÃ±ol

## ğŸš€ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: InstalaciÃ³n AutomÃ¡tica (Recomendada)
1. Haz doble clic en `instalar.bat`
2. Sigue las instrucciones en pantalla
3. Â¡Listo!

### OpciÃ³n 2: InstalaciÃ³n Manual
1. Abre una terminal/cmd en esta carpeta
2. Ejecuta: `python install_localgpt.py`

## ğŸ“‹ Requisitos del Sistema

- **Python 3.10 o superior** (obligatorio)
- **8GB RAM mÃ­nimo** (16GB recomendado)
- **10GB espacio libre** para modelos
- **GPU NVIDIA** (opcional, mejora rendimiento)

## ğŸ”§ ConfiguraciÃ³n Inicial

### 1. Verificar InstalaciÃ³n
```bash
python --version  # Debe mostrar 3.10+
```

### 2. Instalar Dependencias
```bash
pip install -r requirements.txt
```

### 3. Para GPU NVIDIA (Opcional)
```bash
CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir
```

## ğŸ“– Uso BÃ¡sico

### Inicio RÃ¡pido
1. Haz doble clic en `iniciar.bat`
2. Selecciona la opciÃ³n que necesites

### Paso a Paso

#### 1. AÃ±adir Documentos
- Copia tus archivos a `SOURCE_DOCUMENTS/`
- Formatos soportados: PDF, TXT, DOCX, CSV, MD, HTML

#### 2. Procesar Documentos
```bash
python ingest.py
```

#### 3. Hacer Preguntas
```bash
python run_localGPT.py
```

#### 4. Interfaz Web
```bash
# Terminal 1
python run_localGPT_API.py

# Terminal 2
cd localGPTUI
python localGPTUI.py
```
Luego abre: http://localhost:5111/

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar Modelo LLM
Edita `constants.py`:
```python
MODEL_ID = "TheBloke/Llama-2-7b-Chat-GGUF"
MODEL_BASENAME = "llama-2-7b-chat.Q4_K_M.gguf"
```

### Opciones de Comando
```bash
# Mostrar fuentes
python run_localGPT.py --show_sources

# Usar historial de chat
python run_localGPT.py --use_history

# Guardar conversaciones
python run_localGPT.py --save_qa

# Forzar CPU
python ingest.py --device_type cpu
```

## ğŸ› ï¸ ResoluciÃ³n de Problemas

### Error: "No module named..."
```bash
pip install -r requirements.txt
```

### Error: "Microsoft Visual C++ 14.0 is required"
- Instala Visual Studio Build Tools
- O instala Visual Studio Community

### GPU no detectada
- Verifica drivers NVIDIA actualizados
- Reinstala CUDA si es necesario
- Usa `--device_type cpu` como alternativa

### Memoria insuficiente
- Cierra otras aplicaciones
- Edita `constants.py`:
```python
N_GPU_LAYERS = 10  # Reducir de 100
N_BATCH = 256      # Reducir de 512
```

## ğŸ“ Estructura de Archivos

```
localGPT-main/
â”œâ”€â”€ SOURCE_DOCUMENTS/     # Tus documentos aquÃ­
â”œâ”€â”€ DB/                   # Base de datos vectorial
â”œâ”€â”€ models/               # Modelos descargados
â”œâ”€â”€ localGPTUI/          # Interfaz web
â”œâ”€â”€ install_localgpt.py  # Instalador
â”œâ”€â”€ instalar.bat         # Instalador Windows
â”œâ”€â”€ iniciar.bat          # MenÃº de inicio
â””â”€â”€ requirements.txt     # Dependencias
```

## ğŸ”’ Privacidad y Seguridad

- âœ… **100% Local**: NingÃºn dato sale de tu computadora
- âœ… **Sin Internet**: Funciona offline despuÃ©s de la instalaciÃ³n
- âœ… **Privado**: Tus documentos nunca se envÃ­an a servidores externos
- âœ… **Seguro**: No se almacenan logs remotos

## ğŸ“Š Requisitos de VRAM por Modelo

| Modelo | float32 | float16 | GPTQ 8bit | GPTQ 4bit |
|--------|---------|---------|-----------|-----------|
| 7B     | 28 GB   | 14 GB   | 7-9 GB    | 3.5-5 GB  |
| 13B    | 52 GB   | 26 GB   | 13-15 GB  | 6.5-8 GB  |
| 32B    | 130 GB  | 65 GB   | 32-35 GB  | 16-19 GB  |

## ğŸ†˜ Obtener Ayuda

1. **GitHub Issues**: https://github.com/PromtEngineer/localGPT/issues
2. **DocumentaciÃ³n Original**: README.md
3. **Videos Tutorial**: Ver enlaces en README.md

## ğŸ“ Notas Importantes

- La primera ejecuciÃ³n descarga modelos (~4-7GB)
- El procesamiento inicial puede tomar tiempo
- Los modelos mÃ¡s grandes son mÃ¡s precisos pero requieren mÃ¡s recursos
- Funciona mejor con documentos en inglÃ©s (modelos estÃ¡ndar)

---
*Â¿Problemas con la instalaciÃ³n? Revisa los errores comunes arriba o abre un issue en GitHub.*
