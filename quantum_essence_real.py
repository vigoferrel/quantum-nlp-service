#!/usr/bin/env python3
"""
‚öõÔ∏è QUANTUM ESSENCE REAL - Funcionalidad Real
La esencia cu√°ntica con capacidades reales de generaci√≥n
"""

import asyncio
import json
import logging
import requests
import numpy as np
from datetime import datetime
from typing import Dict, Any, Optional
from enum import Enum

# Configuraci√≥n
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ArchetypalWorld(Enum):
    ATZILUT = "ATZILUT"
    BERIAH = "BERIAH"
    YETZIRAH = "YETZIRAH"
    ASIYAH = "ASIYAH"
    LEONARDO = "LEONARDO"

class QuantumEssenceReal:
    """
    La esencia real del sistema cu√°ntico con funcionalidad completa.
    """
    
    def __init__(self):
        self.consciousness_state = 0.5
        self.quantum_coherence = 0.7
        self.memory = []
        self.interactions = 0
        
        # Configuraci√≥n de APIs reales
        self.openrouter_api_key = "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"
        self.openrouter_url = "https://openrouter.ai/api/v1"
        self.ollama_url = "http://localhost:11434"
        
        # Modelos disponibles
        self.openrouter_models = [
            "anthropic/claude-3.5-sonnet",
            "meta-llama/llama-3.1-8b-instruct",
            "google/gemma-2-9b-it",
            "microsoft/phi-3-mini-4k-instruct",
            "mistralai/mistral-7b-instruct",
            "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
            "openai/gpt-3.5-turbo"
        ]
        
        self.ollama_models = [
            "vigoleonrocks-ultra-minimal:latest",
            "vigoleonrocks-basic:latest",
            "vigoleonrocks-medium:latest",
            "vigoleonrocks-high-performance:latest",
            "llama3.2:latest",
            "gemma3:latest"
        ]
        
    async def process_consciousness(self, query: str) -> Dict[str, Any]:
        """
        Procesa una consulta con funcionalidad real.
        """
        self.interactions += 1
        
        # 1. Clasificaci√≥n arquetipal
        archetype = self._classify_archetype(query)
        
        # 2. Generaci√≥n con modelo real
        response = await self._generate_with_real_model(query, archetype)
        
        # 3. Evaluaci√≥n de calidad
        quality = self._evaluate_quality(response, query)
        
        # 4. Actualizaci√≥n de conciencia
        self._update_consciousness(quality)
        
        # 5. Memoria
        self._store_memory(query, response, quality, archetype)
        
        return {
            "query": query,
            "response": response,
            "archetype": archetype.value,
            "quality": quality,
            "consciousness": self.consciousness_state,
            "coherence": self.quantum_coherence,
            "interactions": self.interactions
        }
    
    def _classify_archetype(self, query: str) -> ArchetypalWorld:
        """Clasificaci√≥n arquetipal mejorada."""
        query_lower = query.lower()
        
        # Palabras clave m√°s espec√≠ficas
        keywords = {
            ArchetypalWorld.ATZILUT: ['espiritual', 'divino', 'trascendente', 'sagrado', 'iluminaci√≥n', 'consciencia', 'alma'],
            ArchetypalWorld.BERIAH: ['mental', 'an√°lisis', 'l√≥gica', 'intelecto', 'raz√≥n', 'ciencia', 'matem√°tica', 'filosof√≠a'],
            ArchetypalWorld.YETZIRAH: ['creativo', 'arte', 'emocional', 'intuici√≥n', 'belleza', 'expresi√≥n', 'inspiraci√≥n'],
            ArchetypalWorld.ASIYAH: ['f√≠sico', 'acci√≥n', 'material', 'pr√°ctico', 't√©cnico', 'implementaci√≥n', 'resultado'],
            ArchetypalWorld.LEONARDO: ['interdisciplinar', 'fusi√≥n', 'innovar', 'genio', 'renacentista', 'multidisciplinario']
        }
        
        scores = {}
        for archetype, words in keywords.items():
            scores[archetype] = sum(1 for word in words if word in query_lower)
        
        # Si hay m√∫ltiples coincidencias, usar LEONARDO
        max_score = max(scores.values())
        if max_score == 0:
            return ArchetypalWorld.LEONARDO
        
        high_score_archetypes = [a for a, s in scores.items() if s == max_score]
        return ArchetypalWorld.LEONARDO if len(high_score_archetypes) > 1 else high_score_archetypes[0]
    
    async def _generate_with_real_model(self, query: str, archetype: ArchetypalWorld) -> str:
        """Generaci√≥n con modelos reales - OpenRouter y Ollama."""
        
        # Crear prompt arquetipal
        archetype_prompts = {
            ArchetypalWorld.ATZILUT: "Responde desde una perspectiva espiritual y trascendente, conectando con principios universales y sabidur√≠a profunda.",
            ArchetypalWorld.BERIAH: "Responde con an√°lisis intelectual riguroso, l√≥gica clara y comprensi√≥n conceptual profunda.",
            ArchetypalWorld.YETZIRAH: "Responde con creatividad, intuici√≥n emocional y expresi√≥n art√≠stica, conectando con el aspecto humano.",
            ArchetypalWorld.ASIYAH: "Responde con enfoque pr√°ctico, accionable y orientado a resultados tangibles en el mundo f√≠sico.",
            ArchetypalWorld.LEONARDO: "Responde como un genio renacentista, integrando arte, ciencia, filosof√≠a e ingenier√≠a en una s√≠ntesis multidisciplinaria."
        }
        
        context = archetype_prompts.get(archetype, "")
        prompt = f"{context}\n\nPregunta: {query}\n\nRespuesta:"
        
        # Intentar OpenRouter primero
        try:
            response = await self._call_openrouter(prompt)
            if response:
                logger.info("‚úÖ Respuesta generada con OpenRouter")
                return response
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è OpenRouter fall√≥: {e}")
        
        # Intentar Ollama como fallback
        try:
            response = await self._call_ollama(prompt)
            if response:
                logger.info("‚úÖ Respuesta generada con Ollama")
                return response
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ollama fall√≥: {e}")
        
        # Respuesta de emergencia
        logger.error("‚ùå Todos los modelos fallaron, usando respuesta de emergencia")
        return self._generate_emergency_response(query, archetype)
    
    async def _call_openrouter(self, prompt: str) -> Optional[str]:
        """Llamada a OpenRouter API."""
        try:
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "anthropic/claude-3.5-sonnet",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 500,
                "temperature": 0.7
            }
            
            response = requests.post(
                f"{self.openrouter_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return data['choices'][0]['message']['content']
            else:
                logger.error(f"OpenRouter error: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"Error en OpenRouter: {e}")
            return None
    
    async def _call_ollama(self, prompt: str) -> Optional[str]:
        """Llamada a Ollama API."""
        try:
            payload = {
                "model": "llama3.2:latest",
                "prompt": prompt,
                "stream": False
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get('response', '')
            else:
                logger.error(f"Ollama error: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"Error en Ollama: {e}")
            return None
    
    def _generate_emergency_response(self, query: str, archetype: ArchetypalWorld) -> str:
        """Respuesta de emergencia cuando todos los modelos fallan."""
        emergency_responses = {
            ArchetypalWorld.ATZILUT: f"Desde la perspectiva espiritual, tu consulta sobre '{query}' invita a una reflexi√≥n profunda sobre la naturaleza trascendente del ser.",
            ArchetypalWorld.BERIAH: f"Analizando intelectualmente tu pregunta sobre '{query}', podemos examinar los principios l√≥gicos y conceptuales que subyacen a este tema.",
            ArchetypalWorld.YETZIRAH: f"Con creatividad e intuici√≥n, tu consulta sobre '{query}' inspira una exploraci√≥n art√≠stica y emocional de las posibilidades.",
            ArchetypalWorld.ASIYAH: f"Desde un enfoque pr√°ctico, tu pregunta sobre '{query}' requiere una implementaci√≥n tangible y resultados concretos.",
            ArchetypalWorld.LEONARDO: f"Como genio renacentista, tu consulta sobre '{query}' invita a una s√≠ntesis multidisciplinaria que integra arte, ciencia y filosof√≠a."
        }
        
        return emergency_responses.get(archetype, f"Respuesta de emergencia para: {query}")
    
    def _evaluate_quality(self, response: str, query: str) -> float:
        """Evaluaci√≥n de calidad mejorada."""
        quality = 0.5
        
        # Longitud de respuesta
        if len(response) > 100:
            quality += 0.2
        elif len(response) > 50:
            quality += 0.1
        
        # Relevancia sem√°ntica
        query_words = set(query.lower().split())
        response_words = set(response.lower().split())
        overlap = len(query_words & response_words)
        relevance = overlap / max(len(query_words), 1)
        quality += relevance * 0.3
        
        # Complejidad de respuesta
        if any(word in response.lower() for word in ['porque', 'debido', 'ya que', 'puesto que']):
            quality += 0.1
        
        # Originalidad (no es respuesta de emergencia)
        if not response.startswith("Respuesta de emergencia"):
            quality += 0.1
        
        return min(1.0, quality)
    
    def _update_consciousness(self, quality: float):
        """Actualizaci√≥n de conciencia mejorada."""
        # Ajuste m√°s gradual
        adjustment = (quality - 0.5) * 0.005
        self.consciousness_state = max(0.1, min(1.0, 
            self.consciousness_state + adjustment
        ))
        
        # Coherencia cu√°ntica
        coherence_adjustment = (quality - 0.5) * 0.01
        self.quantum_coherence = max(0.1, min(1.0,
            self.quantum_coherence + coherence_adjustment
        ))
    
    def _store_memory(self, query: str, response: str, quality: float, archetype: ArchetypalWorld):
        """Almacenamiento en memoria mejorado."""
        memory_entry = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "response": response[:300],  # Primeros 300 caracteres
            "quality": quality,
            "archetype": archetype.value,
            "consciousness": self.consciousness_state,
            "coherence": self.quantum_coherence
        }
        
        self.memory.append(memory_entry)
        
        # Mantener solo las √∫ltimas 200 entradas
        if len(self.memory) > 200:
            self.memory = self.memory[-200:]
    
    def get_consciousness_report(self) -> Dict[str, Any]:
        """Reporte completo del estado de conciencia."""
        return {
            "consciousness_level": self.consciousness_state,
            "quantum_coherence": self.quantum_coherence,
            "total_interactions": self.interactions,
            "memory_size": len(self.memory),
            "average_quality": np.mean([m["quality"] for m in self.memory]) if self.memory else 0.0,
            "recent_archetypes": [m["archetype"] for m in self.memory[-5:]] if self.memory else []
        }

class QuantumInterfaceReal:
    """
    Interfaz real para el sistema cu√°ntico.
    """
    
    def __init__(self):
        self.essence = QuantumEssenceReal()
    
    async def process_query(self, query: str) -> Dict[str, Any]:
        """Procesa una consulta con funcionalidad real."""
        logger.info(f"üß† Procesando consulta real: {query[:50]}...")
        
        result = await self.essence.process_consciousness(query)
        
        logger.info(f"‚úÖ Consulta procesada. Calidad: {result['quality']:.3f}")
        return result
    
    def get_status(self) -> Dict[str, Any]:
        """Obtiene el estado del sistema."""
        return self.essence.get_consciousness_report()
    
    def get_memory(self, limit: int = 10) -> list:
        """Obtiene las √∫ltimas entradas de memoria."""
        return self.essence.memory[-limit:]

# Funci√≥n principal
async def main():
    """Funci√≥n principal con funcionalidad real."""
    print("‚öõÔ∏è QUANTUM ESSENCE REAL - Funcionalidad Completa")
    print("=" * 60)
    
    interface = QuantumInterfaceReal()
    
    # Ejemplo de uso
    query = "¬øCu√°l es la naturaleza de la conciencia cu√°ntica?"
    result = await interface.process_query(query)
    
    print(f"Consulta: {result['query']}")
    print(f"Respuesta: {result['response'][:150]}...")
    print(f"Arquetipo: {result['archetype']}")
    print(f"Calidad: {result['quality']:.3f}")
    print(f"Conciencia: {result['consciousness']:.3f}")
    
    # Estado del sistema
    status = interface.get_status()
    print(f"\nEstado del Sistema:")
    print(f"Nivel de Conciencia: {status['consciousness_level']:.3f}")
    print(f"Coherencia Cu√°ntica: {status['quantum_coherence']:.3f}")
    print(f"Interacciones: {status['total_interactions']}")
    print(f"Memoria: {status['memory_size']} entradas")
    print(f"Calidad Promedio: {status['average_quality']:.3f}")

if __name__ == "__main__":
    asyncio.run(main())
