#!/usr/bin/env python3
"""
Script de instalaci√≥n para localGPT
Automatiza el proceso de instalaci√≥n de dependencias y configuraci√≥n inicial
"""

import subprocess
import sys
import os
import platform

def run_command(command, check=True):
    """Ejecuta un comando y muestra la salida"""
    print(f"\n>>> Ejecutando: {command}")
    try:
        result = subprocess.run(command, shell=True, check=check, 
                              capture_output=True, text=True)
        if result.stdout:
            print(result.stdout)
        return result.returncode == 0
    except subprocess.CalledProcessError as e:
        print(f"Error ejecutando comando: {e}")
        if e.stderr:
            print(f"Error: {e.stderr}")
        return False

def check_python_version():
    """Verifica que Python sea 3.10 o superior"""
    version = sys.version_info
    print(f"Versi√≥n de Python detectada: {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 10):
        print("‚ùå ERROR: Se requiere Python 3.10 o superior")
        print("Por favor instala Python 3.10+ desde https://python.org")
        return False
    
    print("‚úÖ Versi√≥n de Python compatible")
    return True

def check_gpu():
    """Detecta si hay GPU NVIDIA disponible"""
    try:
        result = subprocess.run("nvidia-smi", shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ GPU NVIDIA detectada")
            print(result.stdout.split('\n')[0])  # Primera l√≠nea con info de la GPU
            return True
    except:
        pass
    
    print("‚ö†Ô∏è  No se detect√≥ GPU NVIDIA, se usar√° CPU")
    return False

def install_requirements():
    """Instala los requerimientos del proyecto"""
    print("\nüîß Instalando dependencias...")
    
    # Actualizar pip
    if not run_command(f"{sys.executable} -m pip install --upgrade pip"):
        print("‚ùå Error actualizando pip")
        return False
    
    # Instalar requirements.txt
    if not run_command(f"{sys.executable} -m pip install -r requirements.txt"):
        print("‚ùå Error instalando requirements.txt")
        return False
    
    return True

def install_llama_cpp(gpu_support=False):
    """Instala llama-cpp-python con soporte GPU si es necesario"""
    print("\nü¶ô Instalando llama-cpp-python...")
    
    if gpu_support and platform.system() == "Windows":
        # Para Windows con GPU NVIDIA
        env_vars = "CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1"
        command = f"{env_vars} {sys.executable} -m pip install llama-cpp-python --no-cache-dir"
    elif platform.system() == "Darwin":  # macOS
        # Para Mac con Metal
        env_vars = "CMAKE_ARGS=\"-DLLAMA_METAL=on\" FORCE_CMAKE=1"
        command = f"{env_vars} {sys.executable} -m pip install llama-cpp-python --no-cache-dir"
    else:
        # CPU solamente
        command = f"{sys.executable} -m pip install llama-cpp-python"
    
    return run_command(command, check=False)  # No fallar si hay error

def create_directories():
    """Crea los directorios necesarios"""
    print("\nüìÅ Creando directorios necesarios...")
    
    directories = [
        "SOURCE_DOCUMENTS",
        "DB", 
        "models",
        "local_chat_history"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"‚úÖ Directorio creado: {directory}")

def download_sample_document():
    """Descarga documento de muestra para testing"""
    print("\nüìÑ Verificando documento de muestra...")
    
    sample_file = "SOURCE_DOCUMENTS/constitucion_muestra.txt"
    if not os.path.exists(sample_file):
        # Crear un documento de muestra simple
        sample_content = """
DOCUMENTO DE MUESTRA PARA LOCALGPT

Este es un documento de prueba para verificar que localGPT funciona correctamente.

LocalGPT es una herramienta que permite hacer preguntas sobre documentos de forma privada y local.

Caracter√≠sticas principales:
- Procesamiento completamente local
- Sin env√≠o de datos a servidores externos  
- Soporte para m√∫ltiples formatos de archivo
- Interfaz de l√≠nea de comandos y web

Para usar localGPT:
1. Coloca tus documentos en la carpeta SOURCE_DOCUMENTS
2. Ejecuta python ingest.py para procesar los documentos
3. Ejecuta python run_localGPT.py para hacer preguntas

¬°Disfruta usando localGPT de forma privada y segura!
"""
        with open(sample_file, 'w', encoding='utf-8') as f:
            f.write(sample_content)
        print(f"‚úÖ Documento de muestra creado: {sample_file}")
    else:
        print(f"‚úÖ Documento de muestra ya existe: {sample_file}")

def show_next_steps():
    """Muestra los siguientes pasos despu√©s de la instalaci√≥n"""
    print("\n" + "="*60)
    print("üéâ ¬°INSTALACI√ìN COMPLETADA!")
    print("="*60)
    print()
    print("üìã SIGUIENTES PASOS:")
    print()
    print("1. üìÑ A√±adir documentos:")
    print("   - Copia tus archivos PDF, TXT, DOCX, etc. a la carpeta SOURCE_DOCUMENTS/")
    print()
    print("2. üîÑ Procesar documentos:")
    print("   python ingest.py")
    print()
    print("3. üí¨ Hacer preguntas:")
    print("   python run_localGPT.py")
    print()
    print("4. üåê Interfaz web (opcional):")
    print("   python run_localGPT_API.py")
    print("   (En otra terminal): python localGPTUI/localGPTUI.py")
    print("   (Abrir navegador): http://localhost:5111/")
    print()
    print("üìö COMANDOS √öTILES:")
    print("   - python run_localGPT.py --help          # Ver opciones")
    print("   - python run_localGPT.py --show_sources  # Mostrar fuentes")
    print("   - python run_localGPT.py --use_history   # Habilitar historial")
    print("   - python ingest.py --device_type cpu     # Forzar uso de CPU")
    print()
    print("‚ö†Ô∏è  NOTAS IMPORTANTES:")
    print("   - La primera ejecuci√≥n descargar√° modelos (requiere internet)")
    print("   - Los modelos pueden ocupar varios GB de espacio")
    print("   - Una vez descargados, funciona sin internet")
    print()
    print("="*60)

def main():
    """Funci√≥n principal de instalaci√≥n"""
    print("üöÄ Iniciando instalaci√≥n de localGPT")
    print("="*50)
    
    # Verificar Python
    if not check_python_version():
        return 1
    
    # Detectar GPU
    has_gpu = check_gpu()
    
    # Instalar dependencias principales
    if not install_requirements():
        print("\n‚ùå Error en la instalaci√≥n de dependencias")
        return 1
    
    # Instalar llama-cpp-python
    if not install_llama_cpp(has_gpu):
        print("\n‚ö†Ô∏è  Advertencia: Error instalando llama-cpp-python")
        print("   Puedes intentar instalarlo manualmente m√°s tarde")
    
    # Crear directorios
    create_directories()
    
    # Crear documento de muestra
    download_sample_document()
    
    # Mostrar siguientes pasos
    show_next_steps()
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
